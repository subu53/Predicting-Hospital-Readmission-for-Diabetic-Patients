{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "624596e0-e8a7-473e-b1c9-9f621e887402",
   "metadata": {},
   "source": [
    "ðŸ©º Predicting Hospital Readmission for Diabetic Patients\n",
    "ðŸ“˜ Project Description\n",
    "This project uses a dataset of over 100,000 records from diabetic patients in 130 U.S. hospitals (1999â€“2008) to predict whether a patient will be readmitted within 30 days of discharge. Hospital readmissions are costly and may indicate poor quality of care. By identifying key risk factors and predicting readmissions, we can help healthcare providers improve outcomes and reduce costs.\n",
    "\n",
    "Steps:\n",
    "\n",
    "Data Cleaning\n",
    "Exploratory Data Analysis (EDA)\n",
    "Model Building (Logistic Regression, Random Forest, XGBoost)\n",
    "Evaluation & Interpretability\n",
    "Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888506ae-d709-4229-9494-68fd73a20b6c",
   "metadata": {},
   "source": [
    "## ðŸ”„ Data Preprocessing\n",
    "\n",
    "ðŸ©º Project Title: Predicting Hospital Readmission for Diabetic Patients ðŸ“˜ Project Description This project leverages the Diabetes 130-US hospitals for years 1999â€“2008 dataset to explore the patterns and factors associated with hospital readmission in diabetic patients. The primary objective is to build a predictive model to determine whether a patient is likely to be readmitted to the hospital within 30 days of dischargeâ€”a critical issue in healthcare management due to its implications on patient outcomes and hospital costs.\n",
    "\n",
    "The dataset includes over 100,000 medical records from diabetic patients across 130 hospitals in the United States, spanning a period of 10 years. It contains demographic information, diagnostic details, treatment regimens, lab results, and hospitalization histories.\n",
    "\n",
    "ðŸŽ¯ Project Objectives Understand and preprocess the dataset to handle missing values, anomalies, and categorical variables.\n",
    "\n",
    "Perform exploratory data analysis (EDA) to uncover significant patterns and correlations.\n",
    "\n",
    "Build and evaluate classification models (e.g., logistic regression, random forest, XGBoost) to predict 30-day readmission.\n",
    "\n",
    "Identify key factors contributing to high readmission risk.\n",
    "\n",
    "Provide actionable insights to healthcare providers for improving discharge planning and patient monitoring.\n",
    "\n",
    "ðŸ“¦ Deliverables Cleaned and well-documented dataset.\n",
    "\n",
    "EDA visualizations and statistical summaries.\n",
    "\n",
    "Machine learning models with evaluation metrics.\n",
    "\n",
    "A final report or dashboard summarizing findings and recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26d25d31-747c-4d8a-80e5-9fb5438e47cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve, roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Set pandas display options for better viewing\n",
    "pd.set_option('display.max_columns', None) # Show all columns\n",
    "pd.set_option('display.max_rows', 100)     # Show more rows if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0e0dac7-a13d-44f4-9a26-19fe0fa8f12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading main data from: C:\\Users\\Sam_Ke\\Downloads\\diabetic_data.csv\n",
      "Main data loaded successfully!\n",
      "ID mapping file loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "data_path = r'C:\\Users\\Sam_Ke\\Downloads\\diabetic_data.csv'       # Main data\n",
    "ids_mapping_path = r'C:\\Users\\Sam_Ke\\Downloads\\IDs_mapping.csv'  # If you have a separate ID mapping file\n",
    "\n",
    "# --- Step 1: Load the data ---\n",
    "print(f\"Loading main data from: {data_path}\")\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(\"Main data loaded successfully!\")\n",
    "\n",
    "    # Try to load ID mappings (optional)\n",
    "    try:\n",
    "        id_map = pd.read_csv(ids_mapping_path)\n",
    "        print(\"ID mapping file loaded successfully!\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"ID mapping file not found. Continuing without it.\")\n",
    "        id_map = None\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {data_path}\")\n",
    "    print(\"Please ensure the file path is correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef178347-f5cb-4905-a616-7a89d851fb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>payer_code</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>diag_1</th>\n",
       "      <th>diag_2</th>\n",
       "      <th>diag_3</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>max_glu_serum</th>\n",
       "      <th>A1Cresult</th>\n",
       "      <th>metformin</th>\n",
       "      <th>repaglinide</th>\n",
       "      <th>nateglinide</th>\n",
       "      <th>chlorpropamide</th>\n",
       "      <th>glimepiride</th>\n",
       "      <th>acetohexamide</th>\n",
       "      <th>glipizide</th>\n",
       "      <th>glyburide</th>\n",
       "      <th>tolbutamide</th>\n",
       "      <th>pioglitazone</th>\n",
       "      <th>rosiglitazone</th>\n",
       "      <th>acarbose</th>\n",
       "      <th>miglitol</th>\n",
       "      <th>troglitazone</th>\n",
       "      <th>tolazamide</th>\n",
       "      <th>examide</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>Pediatrics-Endocrinology</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.83</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>250.01</td>\n",
       "      <td>255</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>648</td>\n",
       "      <td>250</td>\n",
       "      <td>V27</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>250.43</td>\n",
       "      <td>403</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>157</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
       "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
       "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
       "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
       "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
       "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
       "\n",
       "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                  6                        25                    1   \n",
       "1                  1                         1                    7   \n",
       "2                  1                         1                    7   \n",
       "3                  1                         1                    7   \n",
       "4                  1                         1                    7   \n",
       "\n",
       "   time_in_hospital payer_code         medical_specialty  num_lab_procedures  \\\n",
       "0                 1          ?  Pediatrics-Endocrinology                  41   \n",
       "1                 3          ?                         ?                  59   \n",
       "2                 2          ?                         ?                  11   \n",
       "3                 2          ?                         ?                  44   \n",
       "4                 1          ?                         ?                  51   \n",
       "\n",
       "   num_procedures  num_medications  number_outpatient  number_emergency  \\\n",
       "0               0                1                  0                 0   \n",
       "1               0               18                  0                 0   \n",
       "2               5               13                  2                 0   \n",
       "3               1               16                  0                 0   \n",
       "4               0                8                  0                 0   \n",
       "\n",
       "   number_inpatient  diag_1  diag_2 diag_3  number_diagnoses max_glu_serum  \\\n",
       "0                 0  250.83       ?      ?                 1           NaN   \n",
       "1                 0     276  250.01    255                 9           NaN   \n",
       "2                 1     648     250    V27                 6           NaN   \n",
       "3                 0       8  250.43    403                 7           NaN   \n",
       "4                 0     197     157    250                 5           NaN   \n",
       "\n",
       "  A1Cresult metformin repaglinide nateglinide chlorpropamide glimepiride  \\\n",
       "0       NaN        No          No          No             No          No   \n",
       "1       NaN        No          No          No             No          No   \n",
       "2       NaN        No          No          No             No          No   \n",
       "3       NaN        No          No          No             No          No   \n",
       "4       NaN        No          No          No             No          No   \n",
       "\n",
       "  acetohexamide glipizide glyburide tolbutamide pioglitazone rosiglitazone  \\\n",
       "0            No        No        No          No           No            No   \n",
       "1            No        No        No          No           No            No   \n",
       "2            No    Steady        No          No           No            No   \n",
       "3            No        No        No          No           No            No   \n",
       "4            No    Steady        No          No           No            No   \n",
       "\n",
       "  acarbose miglitol troglitazone tolazamide examide citoglipton insulin  \\\n",
       "0       No       No           No         No      No          No      No   \n",
       "1       No       No           No         No      No          No      Up   \n",
       "2       No       No           No         No      No          No      No   \n",
       "3       No       No           No         No      No          No      Up   \n",
       "4       No       No           No         No      No          No  Steady   \n",
       "\n",
       "  glyburide-metformin glipizide-metformin glimepiride-pioglitazone  \\\n",
       "0                  No                  No                       No   \n",
       "1                  No                  No                       No   \n",
       "2                  No                  No                       No   \n",
       "3                  No                  No                       No   \n",
       "4                  No                  No                       No   \n",
       "\n",
       "  metformin-rosiglitazone metformin-pioglitazone change diabetesMed readmitted  \n",
       "0                      No                     No     No          No         NO  \n",
       "1                      No                     No     Ch         Yes        >30  \n",
       "2                      No                     No     No         Yes         NO  \n",
       "3                      No                     No     Ch         Yes         NO  \n",
       "4                      No                     No     Ch         Yes         NO  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Explore Data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbdb70ea-76c8-4cc9-b315-204bf1cabf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   encounter_id              101766 non-null  int64 \n",
      " 1   patient_nbr               101766 non-null  int64 \n",
      " 2   race                      101766 non-null  object\n",
      " 3   gender                    101766 non-null  object\n",
      " 4   age                       101766 non-null  object\n",
      " 5   weight                    101766 non-null  object\n",
      " 6   admission_type_id         101766 non-null  int64 \n",
      " 7   discharge_disposition_id  101766 non-null  int64 \n",
      " 8   admission_source_id       101766 non-null  int64 \n",
      " 9   time_in_hospital          101766 non-null  int64 \n",
      " 10  payer_code                101766 non-null  object\n",
      " 11  medical_specialty         101766 non-null  object\n",
      " 12  num_lab_procedures        101766 non-null  int64 \n",
      " 13  num_procedures            101766 non-null  int64 \n",
      " 14  num_medications           101766 non-null  int64 \n",
      " 15  number_outpatient         101766 non-null  int64 \n",
      " 16  number_emergency          101766 non-null  int64 \n",
      " 17  number_inpatient          101766 non-null  int64 \n",
      " 18  diag_1                    101766 non-null  object\n",
      " 19  diag_2                    101766 non-null  object\n",
      " 20  diag_3                    101766 non-null  object\n",
      " 21  number_diagnoses          101766 non-null  int64 \n",
      " 22  max_glu_serum             5346 non-null    object\n",
      " 23  A1Cresult                 17018 non-null   object\n",
      " 24  metformin                 101766 non-null  object\n",
      " 25  repaglinide               101766 non-null  object\n",
      " 26  nateglinide               101766 non-null  object\n",
      " 27  chlorpropamide            101766 non-null  object\n",
      " 28  glimepiride               101766 non-null  object\n",
      " 29  acetohexamide             101766 non-null  object\n",
      " 30  glipizide                 101766 non-null  object\n",
      " 31  glyburide                 101766 non-null  object\n",
      " 32  tolbutamide               101766 non-null  object\n",
      " 33  pioglitazone              101766 non-null  object\n",
      " 34  rosiglitazone             101766 non-null  object\n",
      " 35  acarbose                  101766 non-null  object\n",
      " 36  miglitol                  101766 non-null  object\n",
      " 37  troglitazone              101766 non-null  object\n",
      " 38  tolazamide                101766 non-null  object\n",
      " 39  examide                   101766 non-null  object\n",
      " 40  citoglipton               101766 non-null  object\n",
      " 41  insulin                   101766 non-null  object\n",
      " 42  glyburide-metformin       101766 non-null  object\n",
      " 43  glipizide-metformin       101766 non-null  object\n",
      " 44  glimepiride-pioglitazone  101766 non-null  object\n",
      " 45  metformin-rosiglitazone   101766 non-null  object\n",
      " 46  metformin-pioglitazone    101766 non-null  object\n",
      " 47  change                    101766 non-null  object\n",
      " 48  diabetesMed               101766 non-null  object\n",
      " 49  readmitted                101766 non-null  object\n",
      "dtypes: int64(13), object(37)\n",
      "memory usage: 38.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c976080b-01f8-4bf5-8a30-3a30f7eb69fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced '?' with NaN in the DataFrame.\n",
      "Dropped columns: ['weight', 'max_glu_serum', 'A1Cresult']\n",
      "DataFrame shape after dropping columns: (101766, 47)\n",
      "Handled missing values in remaining columns.\n",
      "\n",
      "DataFrame Info after handling initial missing values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 47 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   encounter_id              101766 non-null  int64 \n",
      " 1   patient_nbr               101766 non-null  int64 \n",
      " 2   race                      101766 non-null  object\n",
      " 3   gender                    101766 non-null  object\n",
      " 4   age                       101766 non-null  object\n",
      " 5   admission_type_id         101766 non-null  int64 \n",
      " 6   discharge_disposition_id  101766 non-null  int64 \n",
      " 7   admission_source_id       101766 non-null  int64 \n",
      " 8   time_in_hospital          101766 non-null  int64 \n",
      " 9   payer_code                101766 non-null  object\n",
      " 10  medical_specialty         101766 non-null  object\n",
      " 11  num_lab_procedures        101766 non-null  int64 \n",
      " 12  num_procedures            101766 non-null  int64 \n",
      " 13  num_medications           101766 non-null  int64 \n",
      " 14  number_outpatient         101766 non-null  int64 \n",
      " 15  number_emergency          101766 non-null  int64 \n",
      " 16  number_inpatient          101766 non-null  int64 \n",
      " 17  diag_1                    101766 non-null  object\n",
      " 18  diag_2                    101766 non-null  object\n",
      " 19  diag_3                    101766 non-null  object\n",
      " 20  number_diagnoses          101766 non-null  int64 \n",
      " 21  metformin                 101766 non-null  object\n",
      " 22  repaglinide               101766 non-null  object\n",
      " 23  nateglinide               101766 non-null  object\n",
      " 24  chlorpropamide            101766 non-null  object\n",
      " 25  glimepiride               101766 non-null  object\n",
      " 26  acetohexamide             101766 non-null  object\n",
      " 27  glipizide                 101766 non-null  object\n",
      " 28  glyburide                 101766 non-null  object\n",
      " 29  tolbutamide               101766 non-null  object\n",
      " 30  pioglitazone              101766 non-null  object\n",
      " 31  rosiglitazone             101766 non-null  object\n",
      " 32  acarbose                  101766 non-null  object\n",
      " 33  miglitol                  101766 non-null  object\n",
      " 34  troglitazone              101766 non-null  object\n",
      " 35  tolazamide                101766 non-null  object\n",
      " 36  examide                   101766 non-null  object\n",
      " 37  citoglipton               101766 non-null  object\n",
      " 38  insulin                   101766 non-null  object\n",
      " 39  glyburide-metformin       101766 non-null  object\n",
      " 40  glipizide-metformin       101766 non-null  object\n",
      " 41  glimepiride-pioglitazone  101766 non-null  object\n",
      " 42  metformin-rosiglitazone   101766 non-null  object\n",
      " 43  metformin-pioglitazone    101766 non-null  object\n",
      " 44  change                    101766 non-null  object\n",
      " 45  diabetesMed               101766 non-null  object\n",
      " 46  readmitted                101766 non-null  object\n",
      "dtypes: int64(13), object(34)\n",
      "memory usage: 36.5+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam_Ke\\AppData\\Local\\Temp\\ipykernel_7608\\2473706936.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['race'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\Sam_Ke\\AppData\\Local\\Temp\\ipykernel_7608\\2473706936.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['payer_code'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\Sam_Ke\\AppData\\Local\\Temp\\ipykernel_7608\\2473706936.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['medical_specialty'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\Sam_Ke\\AppData\\Local\\Temp\\ipykernel_7608\\2473706936.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['diag_1'].fillna('Missing Diagnosis', inplace=True)\n",
      "C:\\Users\\Sam_Ke\\AppData\\Local\\Temp\\ipykernel_7608\\2473706936.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['diag_2'].fillna('Missing Diagnosis', inplace=True)\n",
      "C:\\Users\\Sam_Ke\\AppData\\Local\\Temp\\ipykernel_7608\\2473706936.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['diag_3'].fillna('Missing Diagnosis', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Replace all '?' values with NaN\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "print(\"Replaced '?' with NaN in the DataFrame.\")\n",
    "\n",
    "# Now, drop columns with high missingness as decided\n",
    "columns_to_drop = ['weight', 'max_glu_serum', 'A1Cresult']\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "print(f\"Dropped columns: {columns_to_drop}\")\n",
    "print(\"DataFrame shape after dropping columns:\", df.shape)\n",
    "\n",
    "# For the remaining columns that had '?', replace NaN with specific categories\n",
    "# Based on our earlier analysis, these were 'race', 'payer_code', 'medical_specialty', 'diag_1', 'diag_2', 'diag_3'\n",
    "df['race'].fillna('Unknown', inplace=True)\n",
    "df['payer_code'].fillna('Unknown', inplace=True)\n",
    "df['medical_specialty'].fillna('Unknown', inplace=True)\n",
    "df['diag_1'].fillna('Missing Diagnosis', inplace=True)\n",
    "df['diag_2'].fillna('Missing Diagnosis', inplace=True)\n",
    "df['diag_3'].fillna('Missing Diagnosis', inplace=True)\n",
    "\n",
    "\n",
    "print(\"Handled missing values in remaining columns.\")\n",
    "\n",
    "# Display info to check non-null counts after handling missing values\n",
    "print(\"\\nDataFrame Info after handling initial missing values:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b31d29b1-c078-4ac6-a286-eed084947b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped identifier columns.\n",
      "DataFrame shape after dropping identifiers: (101766, 45)\n"
     ]
    }
   ],
   "source": [
    "# Drop identifier columns\n",
    "df= df.drop(['encounter_id', 'patient_nbr'], axis=1)\n",
    "\n",
    "print(\"Dropped identifier columns.\")\n",
    "print(\"DataFrame shape after dropping identifiers:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "669e8497-d4f8-4ba1-813d-cd18591b468c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101766, 45)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b89c0bce-4ccf-417f-b8ee-ec65ad32f7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 45 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   race                      101766 non-null  object\n",
      " 1   gender                    101766 non-null  object\n",
      " 2   age                       101766 non-null  object\n",
      " 3   admission_type_id         101766 non-null  int64 \n",
      " 4   discharge_disposition_id  101766 non-null  int64 \n",
      " 5   admission_source_id       101766 non-null  int64 \n",
      " 6   time_in_hospital          101766 non-null  int64 \n",
      " 7   payer_code                101766 non-null  object\n",
      " 8   medical_specialty         101766 non-null  object\n",
      " 9   num_lab_procedures        101766 non-null  int64 \n",
      " 10  num_procedures            101766 non-null  int64 \n",
      " 11  num_medications           101766 non-null  int64 \n",
      " 12  number_outpatient         101766 non-null  int64 \n",
      " 13  number_emergency          101766 non-null  int64 \n",
      " 14  number_inpatient          101766 non-null  int64 \n",
      " 15  diag_1                    101766 non-null  object\n",
      " 16  diag_2                    101766 non-null  object\n",
      " 17  diag_3                    101766 non-null  object\n",
      " 18  number_diagnoses          101766 non-null  int64 \n",
      " 19  metformin                 101766 non-null  object\n",
      " 20  repaglinide               101766 non-null  object\n",
      " 21  nateglinide               101766 non-null  object\n",
      " 22  chlorpropamide            101766 non-null  object\n",
      " 23  glimepiride               101766 non-null  object\n",
      " 24  acetohexamide             101766 non-null  object\n",
      " 25  glipizide                 101766 non-null  object\n",
      " 26  glyburide                 101766 non-null  object\n",
      " 27  tolbutamide               101766 non-null  object\n",
      " 28  pioglitazone              101766 non-null  object\n",
      " 29  rosiglitazone             101766 non-null  object\n",
      " 30  acarbose                  101766 non-null  object\n",
      " 31  miglitol                  101766 non-null  object\n",
      " 32  troglitazone              101766 non-null  object\n",
      " 33  tolazamide                101766 non-null  object\n",
      " 34  examide                   101766 non-null  object\n",
      " 35  citoglipton               101766 non-null  object\n",
      " 36  insulin                   101766 non-null  object\n",
      " 37  glyburide-metformin       101766 non-null  object\n",
      " 38  glipizide-metformin       101766 non-null  object\n",
      " 39  glimepiride-pioglitazone  101766 non-null  object\n",
      " 40  metformin-rosiglitazone   101766 non-null  object\n",
      " 41  metformin-pioglitazone    101766 non-null  object\n",
      " 42  change                    101766 non-null  object\n",
      " 43  diabetesMed               101766 non-null  object\n",
      " 44  readmitted                101766 non-null  object\n",
      "dtypes: int64(11), object(34)\n",
      "memory usage: 34.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "721df1c0-f0a4-4a27-ade9-d05816bf6995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['glimepiride'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c21663b0-c8a8-4e14-8173-4814c98dfc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "glimepiride\n",
       "No        96575\n",
       "Steady     4670\n",
       "Up          327\n",
       "Down        194\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['glimepiride'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19f335b5-e9b9-4eec-9534-4a621501f7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "glimepiride-pioglitazone\n",
       "No        101765\n",
       "Steady         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['glimepiride-pioglitazone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3faa303b-8056-4131-a905-043e93ff2c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metformin-pioglitazone\n",
       "No        101765\n",
       "Steady         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['metformin-pioglitazone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f438750a-3328-4f95-ad46-9ed45b61ca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for 'medical_specialty' after grouping rare categories (showing top 10):\n",
      "| medical_specialty          |   count |\n",
      "|:---------------------------|--------:|\n",
      "| Unknown                    |   49949 |\n",
      "| InternalMedicine           |   14635 |\n",
      "| Other                      |    8340 |\n",
      "| Emergency/Trauma           |    7565 |\n",
      "| Family/GeneralPractice     |    7440 |\n",
      "| Cardiology                 |    5352 |\n",
      "| Surgery-General            |    3099 |\n",
      "| Nephrology                 |    1613 |\n",
      "| Orthopedics                |    1400 |\n",
      "| Orthopedics-Reconstructive |    1233 |\n",
      "Number of unique values in 'medical_specialty' after grouping: 11\n",
      "\n",
      "Value counts for 'payer_code' after grouping rare categories (showing top 10):\n",
      "| payer_code   |   count |\n",
      "|:-------------|--------:|\n",
      "| Unknown      |   40256 |\n",
      "| MC           |   32439 |\n",
      "| HM           |    6274 |\n",
      "| SP           |    5007 |\n",
      "| BC           |    4655 |\n",
      "| MD           |    3532 |\n",
      "| CP           |    2533 |\n",
      "| UN           |    2448 |\n",
      "| CM           |    1937 |\n",
      "| Other        |    1652 |\n",
      "Number of unique values in 'payer_code' after grouping: 11\n",
      "\n",
      "Value counts for 'discharge_disposition_id' after grouping rare categories (showing top 10):\n",
      "| discharge_disposition_id   |   count |\n",
      "|:---------------------------|--------:|\n",
      "| 1                          |   60234 |\n",
      "| 3                          |   13954 |\n",
      "| 6                          |   12902 |\n",
      "| Other                      |    4038 |\n",
      "| 18                         |    3691 |\n",
      "| 2                          |    2128 |\n",
      "| 22                         |    1993 |\n",
      "| 11                         |    1642 |\n",
      "| 5                          |    1184 |\n",
      "Number of unique values in 'discharge_disposition_id' after grouping: 9\n"
     ]
    }
   ],
   "source": [
    "# Define a threshold for rare categories (e.g., less than 1% of the total number of records)\n",
    "threshold = len(df) * 0.01 # 1%\n",
    "\n",
    "# Columns to check for rare categories\n",
    "cols_to_group_rare = ['medical_specialty', 'payer_code', 'discharge_disposition_id']\n",
    "\n",
    "for col in cols_to_group_rare:\n",
    "    # Get value counts for the column\n",
    "    value_counts = df[col].value_counts()\n",
    "    # Identify rare categories\n",
    "    rare_categories = value_counts[value_counts < threshold].index\n",
    "    # Replace rare categories with 'Other'\n",
    "    df[col] = df[col].replace(rare_categories, 'Other')\n",
    "\n",
    "    print(f\"\\nValue counts for '{col}' after grouping rare categories (showing top 10):\")\n",
    "    print(df[col].value_counts().head(10).to_markdown()) # Displaying top 10\n",
    "    print(f\"Number of unique values in '{col}' after grouping:\", df[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fdaf299-e2e9-45db-8f71-ee135db633c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diag_1\n",
       "428    6862\n",
       "414    6581\n",
       "786    4016\n",
       "410    3614\n",
       "486    3508\n",
       "       ... \n",
       "373       1\n",
       "314       1\n",
       "684       1\n",
       "217       1\n",
       "V51       1\n",
       "Name: count, Length: 717, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diag_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2f0c131-208b-4bdf-a75b-0bb9a79465f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diag_2\n",
       "276     6752\n",
       "428     6662\n",
       "250     6071\n",
       "427     5036\n",
       "401     3736\n",
       "        ... \n",
       "E918       1\n",
       "46         1\n",
       "V13        1\n",
       "E850       1\n",
       "927        1\n",
       "Name: count, Length: 749, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diag_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6740bcf-1ff7-42e8-b1fc-26975b838562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diag_1    717\n",
       "diag_2    749\n",
       "diag_3    790\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['diag_1', 'diag_2', 'diag_3' ]].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d503f1c-41ae-482d-9b76-8d7df13526e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for 'diag_1' after grouping rare individual codes (showing top 10):\n",
      "| diag_1         |   count |\n",
      "|:---------------|--------:|\n",
      "| 428            |    6862 |\n",
      "| 414            |    6581 |\n",
      "| Rare Diagnosis |    5563 |\n",
      "| 786            |    4016 |\n",
      "| 410            |    3614 |\n",
      "| 486            |    3508 |\n",
      "| 427            |    2766 |\n",
      "| 491            |    2275 |\n",
      "| 715            |    2151 |\n",
      "| 682            |    2042 |\n",
      "Number of unique values in 'diag_1' after grouping: 212\n",
      "\n",
      "Value counts for 'diag_2' after grouping rare individual codes (showing top 10):\n",
      "| diag_2         |   count |\n",
      "|:---------------|--------:|\n",
      "| 276            |    6752 |\n",
      "| 428            |    6662 |\n",
      "| 250            |    6071 |\n",
      "| Rare Diagnosis |    5549 |\n",
      "| 427            |    5036 |\n",
      "| 401            |    3736 |\n",
      "| 496            |    3305 |\n",
      "| 599            |    3288 |\n",
      "| 403            |    2823 |\n",
      "| 414            |    2650 |\n",
      "Number of unique values in 'diag_2' after grouping: 192\n",
      "\n",
      "Value counts for 'diag_3' after grouping rare individual codes (showing top 10):\n",
      "| diag_3         |   count |\n",
      "|:---------------|--------:|\n",
      "| 250            |   11555 |\n",
      "| 401            |    8289 |\n",
      "| Rare Diagnosis |    5788 |\n",
      "| 276            |    5175 |\n",
      "| 428            |    4577 |\n",
      "| 427            |    3955 |\n",
      "| 414            |    3664 |\n",
      "| 496            |    2605 |\n",
      "| 403            |    2357 |\n",
      "| 585            |    1992 |\n",
      "Number of unique values in 'diag_3' after grouping: 198\n"
     ]
    }
   ],
   "source": [
    "# Columns for diagnosis codes\n",
    "diag_cols = ['diag_1', 'diag_2', 'diag_3']\n",
    "\n",
    "# Define a threshold for rare individual diagnosis codes (e.g., less than 50 occurrences)\n",
    "# You can adjust this threshold\n",
    "diag_threshold = 50\n",
    "\n",
    "for col in diag_cols:\n",
    "    # Get value counts for the column\n",
    "    value_counts = df[col].value_counts()\n",
    "    # Identify rare individual codes (excluding the 'Missing Diagnosis' category)\n",
    "    rare_codes = value_counts[(value_counts < diag_threshold) & (value_counts.index != 'Missing Diagnosis')].index\n",
    "    # Replace rare codes with 'Rare Diagnosis'\n",
    "    df[col] = df[col].replace(rare_codes, 'Rare Diagnosis')\n",
    "\n",
    "    print(f\"\\nValue counts for '{col}' after grouping rare individual codes (showing top 10):\")\n",
    "    print(df[col].value_counts().head(10).to_markdown()) # Displaying top 10\n",
    "    print(f\"Number of unique values in '{col}' after grouping:\", df[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e65ba49-3663-46f7-b625-bfb2312ede90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created aggregate medication features: 'num_active_meds' and 'num_med_changes'.\n",
      "\n",
      "Individual medication columns kept (>= 100 active instances): ['metformin', 'repaglinide', 'nateglinide', 'glimepiride', 'glipizide', 'glyburide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'insulin', 'glyburide-metformin']\n",
      "Individual medication columns dropped (< 100 active instances): ['chlorpropamide', 'acetohexamide', 'tolbutamide', 'miglitol', 'troglitazone', 'tolazamide', 'examide', 'citoglipton', 'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone']\n",
      "DataFrame shape after handling individual medication columns: (101766, 35)\n",
      "\n",
      "Value counts for kept individual medication columns:\n",
      "\n",
      "Value counts for 'metformin':\n",
      "| metformin   |   count |\n",
      "|:------------|--------:|\n",
      "| No          |   81778 |\n",
      "| Steady      |   18346 |\n",
      "| Up          |    1067 |\n",
      "| Down        |     575 |\n",
      "\n",
      "Value counts for 'repaglinide':\n",
      "| repaglinide   |   count |\n",
      "|:--------------|--------:|\n",
      "| No            |  100227 |\n",
      "| Steady        |    1384 |\n",
      "| Up            |     110 |\n",
      "| Down          |      45 |\n",
      "\n",
      "Value counts for 'nateglinide':\n",
      "| nateglinide   |   count |\n",
      "|:--------------|--------:|\n",
      "| No            |  101063 |\n",
      "| Steady        |     668 |\n",
      "| Up            |      24 |\n",
      "| Down          |      11 |\n",
      "\n",
      "Value counts for 'glimepiride':\n",
      "| glimepiride   |   count |\n",
      "|:--------------|--------:|\n",
      "| No            |   96575 |\n",
      "| Steady        |    4670 |\n",
      "| Up            |     327 |\n",
      "| Down          |     194 |\n",
      "\n",
      "Value counts for 'glipizide':\n",
      "| glipizide   |   count |\n",
      "|:------------|--------:|\n",
      "| No          |   89080 |\n",
      "| Steady      |   11356 |\n",
      "| Up          |     770 |\n",
      "| Down        |     560 |\n",
      "\n",
      "Value counts for 'glyburide':\n",
      "| glyburide   |   count |\n",
      "|:------------|--------:|\n",
      "| No          |   91116 |\n",
      "| Steady      |    9274 |\n",
      "| Up          |     812 |\n",
      "| Down        |     564 |\n",
      "\n",
      "Value counts for 'pioglitazone':\n",
      "| pioglitazone   |   count |\n",
      "|:---------------|--------:|\n",
      "| No             |   94438 |\n",
      "| Steady         |    6976 |\n",
      "| Up             |     234 |\n",
      "| Down           |     118 |\n",
      "\n",
      "Value counts for 'rosiglitazone':\n",
      "| rosiglitazone   |   count |\n",
      "|:----------------|--------:|\n",
      "| No              |   95401 |\n",
      "| Steady          |    6100 |\n",
      "| Up              |     178 |\n",
      "| Down            |      87 |\n",
      "\n",
      "Value counts for 'acarbose':\n",
      "| acarbose   |   count |\n",
      "|:-----------|--------:|\n",
      "| No         |  101458 |\n",
      "| Steady     |     295 |\n",
      "| Up         |      10 |\n",
      "| Down       |       3 |\n",
      "\n",
      "Value counts for 'insulin':\n",
      "| insulin   |   count |\n",
      "|:----------|--------:|\n",
      "| No        |   47383 |\n",
      "| Steady    |   30849 |\n",
      "| Down      |   12218 |\n",
      "| Up        |   11316 |\n",
      "\n",
      "Value counts for 'glyburide-metformin':\n",
      "| glyburide-metformin   |   count |\n",
      "|:----------------------|--------:|\n",
      "| No                    |  101060 |\n",
      "| Steady                |     692 |\n",
      "| Up                    |       8 |\n",
      "| Down                  |       6 |\n"
     ]
    }
   ],
   "source": [
    "# List of all individual medication columns\n",
    "medication_cols = [\n",
    "    'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',\n",
    "    'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone',\n",
    "    'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide',\n",
    "    'examide', 'citoglipton', 'insulin', 'glyburide-metformin', 'glipizide-metformin',\n",
    "    'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone'\n",
    "]\n",
    "\n",
    "# Create aggregate medication features (as discussed)\n",
    "df['num_active_meds'] = df[medication_cols].apply(lambda row: row.isin(['Steady', 'Up', 'Down']).sum(), axis=1)\n",
    "df['num_med_changes'] = df[medication_cols].apply(lambda row: row.isin(['Up', 'Down']).sum(), axis=1)\n",
    "\n",
    "print(\"Created aggregate medication features: 'num_active_meds' and 'num_med_changes'.\")\n",
    "\n",
    "\n",
    "# --- Selective Keeping/Dropping of Individual Medication Columns ---\n",
    "\n",
    "# Define a threshold for keeping individual medication columns\n",
    "# Let's set a threshold, e.g., a medication must have at least 100 non-'No' instances to be kept\n",
    "med_threshold = 100\n",
    "\n",
    "# Identify individual medication columns to keep based on the threshold\n",
    "med_cols_to_keep = []\n",
    "med_cols_to_drop = []\n",
    "\n",
    "for col in medication_cols:\n",
    "    # Count non-'No' and non-'?' instances for the current medication column\n",
    "    # Assuming '?' was replaced by Unknown earlier, but if it's still '?', count accordingly\n",
    "    # Let's count any status other than 'No' or 'Unknown' (if '?' was mapped to Unknown)\n",
    "    # Or, more simply, count instances of 'Steady', 'Up', 'Down'\n",
    "    non_no_count = df[col].isin(['Steady', 'Up', 'Down']).sum() # Count active statuses\n",
    "\n",
    "    if non_no_count >= med_threshold:\n",
    "        med_cols_to_keep.append(col)\n",
    "    else:\n",
    "        med_cols_to_drop.append(col)\n",
    "\n",
    "# Drop the individual medication columns that do not meet the threshold\n",
    "df.drop(med_cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(f\"\\nIndividual medication columns kept (>= {med_threshold} active instances): {med_cols_to_keep}\")\n",
    "print(f\"Individual medication columns dropped (< {med_threshold} active instances): {med_cols_to_drop}\")\n",
    "print(\"DataFrame shape after handling individual medication columns:\", df.shape)\n",
    "\n",
    "# Display value counts for the kept individual medication columns to verify\n",
    "print(\"\\nValue counts for kept individual medication columns:\")\n",
    "for col in med_cols_to_keep:\n",
    "    print(f\"\\nValue counts for '{col}':\")\n",
    "    print(df[col].value_counts().to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f68c43a8-81cf-4fbb-b607-3fb8728bca3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created engineered prior visit features: 'total_prior_visits', 'has_outpatient_prior', 'has_emergency_prior', 'has_inpatient_prior'.\n",
      "\n",
      "DataFrame head with new prior visit features:\n",
      "| number_outpatient   | number_emergency   | number_inpatient   | total_prior_visits   | has_outpatient_prior   | has_emergency_prior   | has_inpatient_prior   |\n",
      "|:--------------------|:-------------------|:-------------------|:---------------------|:-----------------------|:----------------------|:----------------------|\n",
      "| 0                   | 0                  | 0                  | 0                    | 0                      | 0                     | 0                     |\n",
      "| 0                   | 0                  | 0                  | 0                    | 0                      | 0                     | 0                     |\n",
      "| 2                   | 0                  | 1                  | 3                    | 1                      | 0                     | 1                     |\n",
      "| 0                   | 0                  | 0                  | 0                    | 0                      | 0                     | 0                     |\n",
      "| 0                   | 0                  | 0                  | 0                    | 0                      | 0                     | 0                     |\n",
      "\n",
      "Dropped original prior visit count columns.\n",
      "DataFrame shape after handling prior visit columns: (101766, 36)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create 'total_prior_visits' feature by summing the three columns\n",
    "df['total_prior_visits'] = df['number_outpatient'] + df['number_emergency'] + df['number_inpatient']\n",
    "\n",
    "# Create binary features for having any prior visit of each type\n",
    "df['has_outpatient_prior'] = (df['number_outpatient'] > 0).astype(int)\n",
    "df['has_emergency_prior'] = (df['number_emergency'] > 0).astype(int)\n",
    "df['has_inpatient_prior'] = (df['number_inpatient'] > 0).astype(int)\n",
    "\n",
    "print(\"Created engineered prior visit features: 'total_prior_visits', 'has_outpatient_prior', 'has_emergency_prior', 'has_inpatient_prior'.\")\n",
    "\n",
    "# Optional: Display the first few rows with the new features\n",
    "print(\"\\nDataFrame head with new prior visit features:\")\n",
    "print(df[['number_outpatient', 'number_emergency', 'number_inpatient',\n",
    "          'total_prior_visits', 'has_outpatient_prior', 'has_emergency_prior',\n",
    "          'has_inpatient_prior']].head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# Drop the original individual prior visit count columns\n",
    "df=df.drop(['number_outpatient', 'number_emergency', 'number_inpatient'], axis=1)\n",
    "\n",
    "print(\"\\nDropped original prior visit count columns.\")\n",
    "print(\"DataFrame shape after handling prior visit columns:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d739d322-c970-4895-9c00-fa16fe1012d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diabetesMed\n",
       "Yes    78363\n",
       "No     23403\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diabetesMed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a1f0892-7241-4517-b885-f14c1c62d0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "change\n",
       "No    54755\n",
       "Ch    47011\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['change'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a6772e5-44be-4583-bcfa-33bd09d82801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped 'diabetesMed' and 'change' columns to 0/1.\n",
      "Mapped 'age' column to numerical values.\n",
      "\n",
      "DataFrame head showing mapped columns:\n",
      "| diabetesMed   | change   | age   |\n",
      "|:--------------|:---------|:------|\n",
      "| 0             | 0        | 5     |\n",
      "| 1             | 1        | 15    |\n",
      "| 1             | 0        | 25    |\n",
      "| 1             | 1        | 35    |\n",
      "| 1             | 1        | 45    |\n",
      "\n",
      "DataFrame Info after mapping:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 36 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   race                      101766 non-null  object\n",
      " 1   gender                    101766 non-null  object\n",
      " 2   age                       101766 non-null  int64 \n",
      " 3   admission_type_id         101766 non-null  int64 \n",
      " 4   discharge_disposition_id  101766 non-null  object\n",
      " 5   admission_source_id       101766 non-null  int64 \n",
      " 6   time_in_hospital          101766 non-null  int64 \n",
      " 7   payer_code                101766 non-null  object\n",
      " 8   medical_specialty         101766 non-null  object\n",
      " 9   num_lab_procedures        101766 non-null  int64 \n",
      " 10  num_procedures            101766 non-null  int64 \n",
      " 11  num_medications           101766 non-null  int64 \n",
      " 12  diag_1                    101766 non-null  object\n",
      " 13  diag_2                    101766 non-null  object\n",
      " 14  diag_3                    101766 non-null  object\n",
      " 15  number_diagnoses          101766 non-null  int64 \n",
      " 16  metformin                 101766 non-null  object\n",
      " 17  repaglinide               101766 non-null  object\n",
      " 18  nateglinide               101766 non-null  object\n",
      " 19  glimepiride               101766 non-null  object\n",
      " 20  glipizide                 101766 non-null  object\n",
      " 21  glyburide                 101766 non-null  object\n",
      " 22  pioglitazone              101766 non-null  object\n",
      " 23  rosiglitazone             101766 non-null  object\n",
      " 24  acarbose                  101766 non-null  object\n",
      " 25  insulin                   101766 non-null  object\n",
      " 26  glyburide-metformin       101766 non-null  object\n",
      " 27  change                    101766 non-null  int64 \n",
      " 28  diabetesMed               101766 non-null  int64 \n",
      " 29  readmitted                101766 non-null  object\n",
      " 30  num_active_meds           101766 non-null  int64 \n",
      " 31  num_med_changes           101766 non-null  int64 \n",
      " 32  total_prior_visits        101766 non-null  int64 \n",
      " 33  has_outpatient_prior      101766 non-null  int32 \n",
      " 34  has_emergency_prior       101766 non-null  int32 \n",
      " 35  has_inpatient_prior       101766 non-null  int32 \n",
      "dtypes: int32(3), int64(13), object(20)\n",
      "memory usage: 26.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Map binary-like columns to 0 and 1\n",
    "df['diabetesMed'] = df['diabetesMed'].map({'Yes': 1, 'No': 0})\n",
    "df['change'] = df['change'].map({'Ch': 1, 'No': 0})\n",
    "\n",
    "print(\"Mapped 'diabetesMed' and 'change' columns to 0/1.\")\n",
    "\n",
    "# Map ordinal 'age' column to numerical values\n",
    "age_mapping = {'[0-10)': 5, '[10-20)': 15, '[20-30)': 25, '[30-40)': 35, '[40-50)': 45,\n",
    "               '[50-60)': 55, '[60-70)': 65, '[70-80)': 75, '[80-90)': 85, '[90-100)': 95}\n",
    "df['age'] = df['age'].map(age_mapping)\n",
    "\n",
    "print(\"Mapped 'age' column to numerical values.\")\n",
    "\n",
    "# Display the first few rows of these columns to verify\n",
    "print(\"\\nDataFrame head showing mapped columns:\")\n",
    "print(df[['diabetesMed', 'change', 'age']].head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# Display info to check data types after mapping\n",
    "print(\"\\nDataFrame Info after mapping:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9de55bd-f093-4867-a3eb-b47512d190e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created binary target variable 'readmitted_within_30_days'.\n",
      "\n",
      "Value counts for the binary target variable:\n",
      "|   readmitted_within_30_days |   count |\n",
      "|----------------------------:|--------:|\n",
      "|                           0 |   90409 |\n",
      "|                           1 |   11357 |\n"
     ]
    }
   ],
   "source": [
    "# Define the binary target variable\n",
    "# Create a new column 'readmitted_within_30_days' which is 1 if 'readmitted' is '<30', and 0 otherwise\n",
    "df['readmitted_within_30_days'] = (df['readmitted'] == '<30').astype(int)\n",
    "\n",
    "print(\"Created binary target variable 'readmitted_within_30_days'.\")\n",
    "\n",
    "# Display the value counts of the new target variable to verify the imbalance\n",
    "print(\"\\nValue counts for the binary target variable:\")\n",
    "print(df['readmitted_within_30_days'].value_counts().to_markdown())\n",
    "\n",
    "# The original 'readmitted' column is no longer needed in our feature set\n",
    "# We will drop it before performing the final encoding on the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb96c1a-a14e-48e0-99a2-b10f9bb7cb26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b39ad082-0d08-448f-b5c8-7ae283404385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped the original 'readmitted' column.\n",
      "DataFrame shape after dropping original target: (101766, 36)\n",
      "\n",
      "Columns to one-hot encode: ['race', 'gender', 'discharge_disposition_id', 'payer_code', 'medical_specialty', 'diag_1', 'diag_2', 'diag_3', 'metformin', 'repaglinide', 'nateglinide', 'glimepiride', 'glipizide', 'glyburide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'insulin', 'glyburide-metformin']\n",
      "\n",
      "First 5 rows of the refined encoded DataFrame (showing some columns):\n",
      "| age   | time_in_hospital   | num_lab_procedures   | total_prior_visits   | has_outpatient_prior   | num_active_meds   | race_Caucasian   | gender_Female   | medical_specialty_InternalMedicine   | payer_code_MC   | diag_1_428   | insulin_Steady   | readmitted_within_30_days   |\n",
      "|:------|:-------------------|:---------------------|:---------------------|:-----------------------|:------------------|:-----------------|:----------------|:-------------------------------------|:----------------|:-------------|:-----------------|:----------------------------|\n",
      "| 5     | 1                  | 41                   | 0                    | 0                      | 0                 | True             | True            | False                                | False           | False        | False            | 0                           |\n",
      "| 15    | 3                  | 59                   | 0                    | 0                      | 1                 | True             | True            | False                                | False           | False        | False            | 0                           |\n",
      "| 25    | 2                  | 11                   | 3                    | 1                      | 1                 | False            | True            | False                                | False           | False        | False            | 0                           |\n",
      "| 35    | 2                  | 44                   | 0                    | 0                      | 1                 | True             | False           | False                                | False           | False        | False            | 0                           |\n",
      "| 45    | 1                  | 51                   | 0                    | 0                      | 2                 | True             | False           | False                                | False           | False        | True             | 0                           |\n",
      "\n",
      "Column information of the refined encoded DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Columns: 703 entries, age to glyburide-metformin_Up\n",
      "dtypes: bool(686), int32(4), int64(13)\n",
      "memory usage: 78.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Drop the original 'readmitted' column\n",
    "df.drop('readmitted', axis=1, inplace=True)\n",
    "\n",
    "print(\"Dropped the original 'readmitted' column.\")\n",
    "print(\"DataFrame shape after dropping original target:\", df.shape)\n",
    "\n",
    "# Identify all remaining categorical columns to encode\n",
    "# These are the columns that are still of 'object' dtype\n",
    "nominal_cols_to_ohe = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "\n",
    "print(f\"\\nColumns to one-hot encode: {nominal_cols_to_ohe}\")\n",
    "\n",
    "# Perform one-hot encoding on the remaining nominal columns\n",
    "# The binary target 'readmitted_within_30_days' is numerical and will not be encoded\n",
    "df_encoded_refined = pd.get_dummies(df, columns=nominal_cols_to_ohe, dummy_na=False)\n",
    "\n",
    "\n",
    "# Display the first 5 rows and the column information of the refined encoded DataFrame\n",
    "print(\"\\nFirst 5 rows of the refined encoded DataFrame (showing some columns):\")\n",
    "# Display a subset of columns for readability, including original numerical and some new one-hot encoded ones\n",
    "sample_cols_to_show = ['age', 'time_in_hospital', 'num_lab_procedures', 'total_prior_visits',\n",
    "                       'has_outpatient_prior', 'num_active_meds',\n",
    "                       'race_Caucasian', 'gender_Female', 'medical_specialty_InternalMedicine',\n",
    "                       'payer_code_MC', 'diag_1_428', 'insulin_Steady', 'readmitted_within_30_days'] # Include the new binary target\n",
    "\n",
    "\n",
    "# Filter for columns that actually exist in the dataframe after encoding\n",
    "existing_cols_to_show = [col for col in sample_cols_to_show if col in df_encoded_refined.columns]\n",
    "\n",
    "# Add any columns that were kept from individual medications if they are not already in sample_cols_to_show\n",
    "# Retrieve the list of kept medication columns from a previous turn or re-identify them if needed\n",
    "# Assuming 'med_cols_to_keep' list from Step 6 is available\n",
    "try:\n",
    "    kept_med_cols_after_handling = med_cols_to_keep # Use the list from the previous step\n",
    "except NameError:\n",
    "    # If med_cols_to_keep is not defined, re-identify based on columns NOT dropped from the original med list\n",
    "    all_med_cols = [\n",
    "        'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',\n",
    "        'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone',\n",
    "        'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide',\n",
    "        'examide', 'citoglipton', 'insulin', 'glyburide-metformin', 'glipizide-metformin',\n",
    "        'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone'\n",
    "    ]\n",
    "    # Find which of the original med cols are still in df after dropping some in Step 6\n",
    "    kept_med_cols_after_handling = [col for col in all_med_cols if col in df_encoded_refined.columns]\n",
    "\n",
    "\n",
    "existing_cols_to_show.extend([col for col in kept_med_cols_after_handling if col not in existing_cols_to_show])\n",
    "\n",
    "# Ensure 'readmitted_within_30_days' is definitely in the list to show if it exists\n",
    "if 'readmitted_within_30_days' in df_encoded_refined.columns and 'readmitted_within_30_days' not in existing_cols_to_show:\n",
    "     existing_cols_to_show.append('readmitted_within_30_days')\n",
    "\n",
    "\n",
    "# Ensure columns actually exist in the *final* df_encoded_refined before trying to show them\n",
    "final_cols_to_show = [col for col in existing_cols_to_show if col in df_encoded_refined.columns]\n",
    "\n",
    "\n",
    "print(df_encoded_refined[final_cols_to_show].head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "\n",
    "print(\"\\nColumn information of the refined encoded DataFrame:\")\n",
    "# Print info in chunks due to large number of columns\n",
    "# Adjust the range based on the actual number of columns in df_encoded_refined\n",
    "df_encoded_refined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "547328f5-89db-4172-aa41-745b6dcb9f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separated features (X) and target (y).\n",
      "Shape of X: (101766, 702)\n",
      "Shape of y: (101766,)\n",
      "\n",
      "Performed stratified train-test split.\n",
      "Shape of X_train: (81412, 702)\n",
      "Shape of X_test: (20354, 702)\n",
      "Shape of y_train: (81412,)\n",
      "Shape of y_test: (20354,)\n",
      "\n",
      "Value counts for y_train:\n",
      "|   readmitted_within_30_days |   count |\n",
      "|----------------------------:|--------:|\n",
      "|                           0 |   72326 |\n",
      "|                           1 |    9086 |\n",
      "\n",
      "Value counts for y_test:\n",
      "|   readmitted_within_30_days |   count |\n",
      "|----------------------------:|--------:|\n",
      "|                           0 |   18083 |\n",
      "|                           1 |    2271 |\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "# X includes all columns except the binary target variable\n",
    "X = df_encoded_refined.drop('readmitted_within_30_days', axis=1)\n",
    "# y is our binary target variable\n",
    "y = df_encoded_refined['readmitted_within_30_days']\n",
    "\n",
    "print(\"Separated features (X) and target (y).\")\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "\n",
    "\n",
    "# Perform stratified train-test split\n",
    "# We'll use a test set size of 20% (common practice) and a random state for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\nPerformed stratified train-test split.\")\n",
    "# Print the shapes of the resulting sets to verify the split\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "\n",
    "# Print the value counts of the target in train and test sets to verify stratification\n",
    "print(\"\\nValue counts for y_train:\")\n",
    "print(y_train.value_counts().to_markdown())\n",
    "\n",
    "print(\"\\nValue counts for y_test:\")\n",
    "print(y_test.value_counts().to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ccc4494-837e-4a47-b0ae-a5228b13cefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Logistic Regression model with class_weight='balanced'.\n",
      "Trained the Logistic Regression model.\n",
      "Made predictions on the test set.\n",
      "\n",
      "Logistic Regression Model Evaluation (with class_weight='balanced'):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.65      0.76     18083\n",
      "           1       0.18      0.60      0.27      2271\n",
      "\n",
      "    accuracy                           0.64     20354\n",
      "   macro avg       0.55      0.62      0.52     20354\n",
      "weighted avg       0.84      0.64      0.71     20354\n",
      "\n",
      "ROC AUC Score: 0.6684\n",
      "F1-score for minority class (Readmitted < 30): 0.2713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "# We set class_weight='balanced' to handle the class imbalance\n",
    "# max_iter is increased to ensure convergence with potentially complex data\n",
    "log_reg = LogisticRegression(solver='liblinear', class_weight='balanced', max_iter=1000, random_state=42)\n",
    "\n",
    "print(\"Initialized Logistic Regression model with class_weight='balanced'.\")\n",
    "\n",
    "# Train the model on the training data\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "print(\"Trained the Logistic Regression model.\")\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = log_reg.predict(X_test)\n",
    "# Get predicted probabilities for ROC AUC\n",
    "y_pred_proba = log_reg.predict_proba(X_test)[:, 1] # Probability of the positive class (class 1)\n",
    "\n",
    "print(\"Made predictions on the test set.\")\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nLogistic Regression Model Evaluation (with class_weight='balanced'):\")\n",
    "\n",
    "# Classification Report provides Precision, Recall, F1-score for both classes\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ROC AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# F1-score specifically for the minority class (class 1)\n",
    "f1_minority = f1_score(y_test, y_pred, pos_label=1)\n",
    "print(f\"F1-score for minority class (Readmitted < 30): {f1_minority:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ad36516-ff13-4793-a857-a63122e7d45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix for Logistic Regression (with class_weight='balanced'):\n",
      "|          |   Predicted 0 |   Predicted 1 |\n",
      "|:---------|--------------:|--------------:|\n",
      "| Actual 0 |         11709 |          6374 |\n",
      "| Actual 1 |           914 |          1357 |\n",
      "\n",
      "True Negatives (TN): 11709\n",
      "False Positives (FP): 6374\n",
      "False Negatives (FN): 914\n",
      "True Positives (TP): 1357\n"
     ]
    }
   ],
   "source": [
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the confusion matrix using a pandas DataFrame for better readability\n",
    "# Rows represent actual classes, columns represent predicted classes\n",
    "cm_df = pd.DataFrame(cm, index=['Actual 0', 'Actual 1'], columns=['Predicted 0', 'Predicted 1'])\n",
    "\n",
    "print(\"\\nConfusion Matrix for Logistic Regression (with class_weight='balanced'):\")\n",
    "print(cm_df.to_markdown())\n",
    "\n",
    "# You can also extract the counts directly\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nTrue Negatives (TN): {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "print(f\"True Positives (TP): {tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf659247-a0a6-4729-a2dc-61ef24270505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying SMOTE to the training data...\n",
      "SMOTE applied.\n",
      "Shape of original y_train: (81412,)\n",
      "Value counts of original y_train:\n",
      "|   readmitted_within_30_days |   count |\n",
      "|----------------------------:|--------:|\n",
      "|                           0 |   72326 |\n",
      "|                           1 |    9086 |\n",
      "\n",
      "Shape of y_train_resampled: (144652,)\n",
      "Value counts of y_train_resampled after SMOTE:\n",
      "|   readmitted_within_30_days |   count |\n",
      "|----------------------------:|--------:|\n",
      "|                           0 |   72326 |\n",
      "|                           1 |   72326 |\n"
     ]
    }
   ],
   "source": [
    "# If you don't have imbalanced-learn installed, uncomment and run the line below\n",
    "# !pip install imbalanced-learn\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Applying SMOTE to the training data...\")\n",
    "\n",
    "# Initialize SMOTE\n",
    "# random_state for reproducibility\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"SMOTE applied.\")\n",
    "print(\"Shape of original y_train:\", y_train.shape)\n",
    "print(\"Value counts of original y_train:\")\n",
    "print(y_train.value_counts().to_markdown())\n",
    "\n",
    "print(\"\\nShape of y_train_resampled:\", y_train_resampled.shape)\n",
    "print(\"Value counts of y_train_resampled after SMOTE:\")\n",
    "print(y_train_resampled.value_counts().to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5305f0e-4960-44e4-bc22-2714298692ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Logistic Regression model on SMOTE-resampled data...\n",
      "Trained Logistic Regression model on resampled data.\n",
      "Made predictions on the original test set.\n",
      "\n",
      "Logistic Regression Model Evaluation (trained with SMOTE):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     18083\n",
      "           1       0.42      0.01      0.02      2271\n",
      "\n",
      "    accuracy                           0.89     20354\n",
      "   macro avg       0.65      0.50      0.48     20354\n",
      "weighted avg       0.84      0.89      0.84     20354\n",
      "\n",
      "ROC AUC Score: 0.6653\n",
      "F1-score for minority class (Readmitted < 30): 0.0172\n",
      "\n",
      "Confusion Matrix for Logistic Regression (trained with SMOTE):\n",
      "|          |   Predicted 0 |   Predicted 1 |\n",
      "|:---------|--------------:|--------------:|\n",
      "| Actual 0 |         18055 |            28 |\n",
      "| Actual 1 |          2251 |            20 |\n",
      "\n",
      "True Negatives (TN): 18055\n",
      "False Positives (FP): 28\n",
      "False Negatives (FN): 2251\n",
      "True Positives (TP): 20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Retraining Logistic Regression model on SMOTE-resampled data...\")\n",
    "\n",
    "# Initialize the Logistic Regression model WITHOUT class_weight='balanced'\n",
    "# because the data is already balanced\n",
    "log_reg_smote = LogisticRegression(solver='liblinear', max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model on the RESAMPLED training data\n",
    "log_reg_smote.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(\"Trained Logistic Regression model on resampled data.\")\n",
    "\n",
    "# Make predictions on the ORIGINAL testing data\n",
    "y_pred_smote = log_reg_smote.predict(X_test)\n",
    "# Get predicted probabilities for ROC AUC on the ORIGINAL testing data\n",
    "y_pred_proba_smote = log_reg_smote.predict_proba(X_test)[:, 1] # Probability of the positive class (class 1)\n",
    "\n",
    "print(\"Made predictions on the original test set.\")\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nLogistic Regression Model Evaluation (trained with SMOTE):\")\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_test, y_pred_smote))\n",
    "\n",
    "# ROC AUC Score\n",
    "roc_auc_smote = roc_auc_score(y_test, y_pred_proba_smote)\n",
    "print(f\"ROC AUC Score: {roc_auc_smote:.4f}\")\n",
    "\n",
    "# F1-score for the minority class (class 1)\n",
    "f1_minority_smote = f1_score(y_test, y_pred_smote, pos_label=1)\n",
    "print(f\"F1-score for minority class (Readmitted < 30): {f1_minority_smote:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_smote = confusion_matrix(y_test, y_pred_smote)\n",
    "cm_smote_df = pd.DataFrame(cm_smote, index=['Actual 0', 'Actual 1'], columns=['Predicted 0', 'Predicted 1'])\n",
    "\n",
    "print(\"\\nConfusion Matrix for Logistic Regression (trained with SMOTE):\")\n",
    "print(cm_smote_df.to_markdown())\n",
    "\n",
    "# Extract and print individual counts\n",
    "tn_smote, fp_smote, fn_smote, tp_smote = cm_smote.ravel()\n",
    "print(f\"\\nTrue Negatives (TN): {tn_smote}\")\n",
    "print(f\"False Positives (FP): {fp_smote}\")\n",
    "print(f\"False Negatives (FN): {fn_smote}\")\n",
    "print(f\"True Positives (TP): {tp_smote}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae38f1ca-1037-4294-8e36-00cb2bfae90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing and training LightGBM model...\n",
      "Calculated scale_pos_weight: 7.96\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 9086, number of negative: 72326\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1676\n",
      "[LightGBM] [Info] Number of data points in the train set: 81412, number of used features: 694\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.111605 -> initscore=-2.074449\n",
      "[LightGBM] [Info] Start training from score -2.074449\n",
      "Trained the LightGBM model.\n",
      "Made predictions on the original test set.\n",
      "\n",
      "LightGBM Model Evaluation (with scale_pos_weight):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.74      0.82     18083\n",
      "           1       0.19      0.49      0.28      2271\n",
      "\n",
      "    accuracy                           0.71     20354\n",
      "   macro avg       0.56      0.62      0.55     20354\n",
      "weighted avg       0.84      0.71      0.76     20354\n",
      "\n",
      "ROC AUC Score: 0.6642\n",
      "F1-score for minority class (Readmitted < 30): 0.2761\n",
      "\n",
      "Confusion Matrix for LightGBM (with scale_pos_weight):\n",
      "|          |   Predicted 0 |   Predicted 1 |\n",
      "|:---------|--------------:|--------------:|\n",
      "| Actual 0 |         13430 |          4653 |\n",
      "| Actual 1 |          1162 |          1109 |\n",
      "\n",
      "True Negatives (TN): 13430\n",
      "False Positives (FP): 4653\n",
      "False Negatives (FN): 1162\n",
      "True Positives (TP): 1109\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Initializing and training LightGBM model...\")\n",
    "\n",
    "# Calculate scale_pos_weight for class imbalance handling\n",
    "# It's the ratio of the number of negative class instances to the number of positive class instances in the training data\n",
    "scale_pos_weight_value = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"Calculated scale_pos_weight: {scale_pos_weight_value:.2f}\")\n",
    "\n",
    "# Initialize the LightGBM Classifier\n",
    "# objective='binary' for binary classification\n",
    "# metric='auc' is a common evaluation metric\n",
    "# scale_pos_weight addresses class imbalance\n",
    "# random_state for reproducibility\n",
    "# n_estimators is set to a reasonable starting point, can be tuned\n",
    "# learning_rate controls the step size, can be tuned\n",
    "lgb_clf = lgb.LGBMClassifier(objective='binary',\n",
    "                             metric='auc',\n",
    "                             scale_pos_weight=scale_pos_weight_value,\n",
    "                             n_estimators=1000, # Increase n_estimators for potentially better performance\n",
    "                             learning_rate=0.05, # Start with a moderate learning rate\n",
    "                             num_leaves=31, # Default, can be tuned\n",
    "                             random_state=42,\n",
    "                             n_jobs=-1) # Use all available cores\n",
    "\n",
    "# Train the model on the ORIGINAL training data (LightGBM handles imbalance with scale_pos_weight)\n",
    "lgb_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Trained the LightGBM model.\")\n",
    "\n",
    "# Make predictions on the ORIGINAL testing data\n",
    "y_pred_lgbm = lgb_clf.predict(X_test)\n",
    "# Get predicted probabilities for ROC AUC on the ORIGINAL testing data\n",
    "y_pred_proba_lgbm = lgb_clf.predict_proba(X_test)[:, 1] # Probability of the positive class (class 1)\n",
    "\n",
    "print(\"Made predictions on the original test set.\")\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nLightGBM Model Evaluation (with scale_pos_weight):\")\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_test, y_pred_lgbm))\n",
    "\n",
    "# ROC AUC Score\n",
    "roc_auc_lgbm = roc_auc_score(y_test, y_pred_proba_lgbm)\n",
    "print(f\"ROC AUC Score: {roc_auc_lgbm:.4f}\")\n",
    "\n",
    "# F1-score for the minority class (class 1)\n",
    "f1_minority_lgbm = f1_score(y_test, y_pred_lgbm, pos_label=1)\n",
    "print(f\"F1-score for minority class (Readmitted < 30): {f1_minority_lgbm:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_lgbm = confusion_matrix(y_test, y_pred_lgbm)\n",
    "cm_lgbm_df = pd.DataFrame(cm_lgbm, index=['Actual 0', 'Actual 1'], columns=['Predicted 0', 'Predicted 1'])\n",
    "\n",
    "print(\"\\nConfusion Matrix for LightGBM (with scale_pos_weight):\")\n",
    "print(cm_lgbm_df.to_markdown())\n",
    "\n",
    "# Extract and print individual counts\n",
    "tn_lgbm, fp_lgbm, fn_lgbm, tp_lgbm = cm_lgbm.ravel()\n",
    "print(f\"\\nTrue Negatives (TN): {tn_lgbm}\")\n",
    "print(f\"False Positives (FP): {fp_lgbm}\")\n",
    "print(f\"False Negatives (FN): {fn_lgbm}\")\n",
    "print(f\"True Positives (TP): {tp_lgbm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdc4ccb-17bc-47ce-856d-3f62b83c8261",
   "metadata": {},
   "source": [
    "Metric\t               LR w/ class_weight\t   LR w/ SMOTE\t             LightGBM w/ scale_pos_weight\n",
    "Precision (Class 1)\t     0.18\t                   0.42\t                         0.19\n",
    "Recall (Class 1)\t     0.60\t                   0.01\t                         0.49\n",
    "F1-score (Class 1)\t     0.27\t                   0.02\t                         0.28\n",
    "ROC AUC\t                 0.6684\t                   0.6653\t                     0.6642\n",
    "Accuracy\t             0.64\t                   0.89\t                         0.71\n",
    "True Positives (TP)\t     1357\t                   20\t                         1109\n",
    "False Positives (FP)\t 6374\t                   28\t                         4653\n",
    "False Negatives (FN)\t 914\t                   2251\t                         1162\n",
    "True Negatives (TN)\t     11709\t                   18055\t                     13430"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9ef282-7aab-482d-81fb-c91363056544",
   "metadata": {},
   "source": [
    "Let's use RandomizedSearchCV to tune some key hyperparameters of the LightGBM model, aiming to optimize the F1-score for the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2042795-ed67-4288-b5a8-a7855982090b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing and training Random Forest model...\n",
      "Trained the Random Forest model.\n",
      "Made predictions on the original test set.\n",
      "\n",
      "Random Forest Model Evaluation (with class_weight='balanced'):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     18083\n",
      "           1       0.70      0.01      0.01      2271\n",
      "\n",
      "    accuracy                           0.89     20354\n",
      "   macro avg       0.79      0.50      0.48     20354\n",
      "weighted avg       0.87      0.89      0.84     20354\n",
      "\n",
      "ROC AUC Score: 0.6763\n",
      "F1-score for minority class (Readmitted < 30): 0.0122\n",
      "\n",
      "Confusion Matrix for Random Forest (with class_weight='balanced'):\n",
      "|          |   Predicted 0 |   Predicted 1 |\n",
      "|:---------|--------------:|--------------:|\n",
      "| Actual 0 |         18077 |             6 |\n",
      "| Actual 1 |          2257 |            14 |\n",
      "\n",
      "True Negatives (TN): 18077\n",
      "False Positives (FP): 6\n",
      "False Negatives (FN): 2257\n",
      "True Positives (TP): 14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Initializing and training Random Forest model...\")\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "# n_estimators is set to a reasonable starting point\n",
    "# class_weight='balanced' addresses class imbalance\n",
    "# random_state for reproducibility\n",
    "# n_jobs=-1 to use all available cores\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, # Number of trees in the forest\n",
    "                              class_weight='balanced', # Handles class imbalance\n",
    "                              random_state=42,\n",
    "                              n_jobs=-1)\n",
    "\n",
    "# Train the model on the ORIGINAL training data\n",
    "# Using class_weight='balanced' is generally preferred over simple oversampling like SMOTE for tree ensembles\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Trained the Random Forest model.\")\n",
    "\n",
    "# Make predictions on the ORIGINAL testing data\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "# Get predicted probabilities for ROC AUC on the ORIGINAL testing data\n",
    "y_pred_proba_rf = rf_clf.predict_proba(X_test)[:, 1] # Probability of the positive class (class 1)\n",
    "\n",
    "print(\"Made predictions on the original test set.\")\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nRandom Forest Model Evaluation (with class_weight='balanced'):\")\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# ROC AUC Score\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_proba_rf)\n",
    "print(f\"ROC AUC Score: {roc_auc_rf:.4f}\")\n",
    "\n",
    "# F1-score for the minority class (class 1)\n",
    "f1_minority_rf = f1_score(y_test, y_pred_rf, pos_label=1)\n",
    "print(f\"F1-score for minority class (Readmitted < 30): {f1_minority_rf:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "cm_rf_df = pd.DataFrame(cm_rf, index=['Actual 0', 'Actual 1'], columns=['Predicted 0', 'Predicted 1'])\n",
    "\n",
    "print(\"\\nConfusion Matrix for Random Forest (with class_weight='balanced'):\")\n",
    "print(cm_rf_df.to_markdown())\n",
    "\n",
    "# Extract and print individual counts\n",
    "tn_rf, fp_rf, fn_rf, tp_rf = cm_rf.ravel()\n",
    "print(f\"\\nTrue Negatives (TN): {tn_rf}\")\n",
    "print(f\"False Positives (FP): {fp_rf}\")\n",
    "print(f\"False Negatives (FN): {fn_rf}\")\n",
    "print(f\"True Positives (TP): {tp_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7d8e0f-2a0b-4971-b2ad-235fa7098485",
   "metadata": {},
   "source": [
    "Metric                        LR w/ class_weight         LR w/ SMOTE     LightGBM w/ scale_pos_weight        Random Forest w/ class_weight\n",
    "\n",
    "Precision (Class 1)          0.18                          0.42                 0.19                               0.70\n",
    "\n",
    "Recall (Class 1)             0.60                          0.01                 0.49                               0.01\n",
    "\n",
    "F1-score (Class 1)           0.27                          0.02                 0.28                               0.01\n",
    "\n",
    "ROC AUC                      0.6684                        0.6653               0.6642                             0.6763\n",
    "\n",
    "Accuracy                     0.64                          0.89                 0.71                               0.89\n",
    "\n",
    "True Positives (TP)         1357                           20                   1109                               14\n",
    "\n",
    "False Positives (FP)        6374                           28                   4653                               6\n",
    "\n",
    "False Negatives (FN)        914                            2251                 1162                               2257\n",
    "\n",
    "True Negatives (TN)         11709                          18055                13430                              18077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32a3eb7-33cf-4898-93b4-74796b157808",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
